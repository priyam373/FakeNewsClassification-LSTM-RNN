# FakeNewsClassification-LSTMRNN

# Project Introduction:
This binary classification model aims to identify if a news is fake or not based on the text present in the data set. 

# Text Pre-Processing:
This involves following steps to deal with the text data

  ## a) Tokenization:
  That is to convert a corpus into words.

  ## b) Stopwords:
  This is to remove words which are meaningless or carry very little meaning.

  ## c) Stemming/Lemmatization
  Stemming and Lemmatization are used for reducing words into their base/root words. Stemming does it by removing suffixes and Lemmatization does it by reducing them into their dictionary base words.

  ## d) Embedding Layer:
  This layer is used to convert words into vectors for the model to learn. This layer is similar to Word2vec which preserves the semantic meaning.
